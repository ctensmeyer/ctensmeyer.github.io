<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.25.1" />
  <meta name="author" content="Chris Tensmeyer">
  <meta name="description" content="Doctoral Student">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-104415404-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  <link rel="alternate" href="https://ctensmeyer.github.io/index.xml" type="application/rss+xml" title="Academic">
  <link rel="feed" href="https://ctensmeyer.github.io/index.xml" type="application/rss+xml" title="Academic">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://ctensmeyer.github.io/">

  

  <title>Academic</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Academic</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about" data-target="#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications_selected" data-target="#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#talks" data-target="#talks">
            
            <span>Talks</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching" data-target="#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact" data-target="#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>



  
  
  <section id="about" class="home-section">
    <div class="container">
      



<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-address">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('https://ctensmeyer.github.io/img/chris.jpg');"></div>
      <meta itemprop="image" content="https://ctensmeyer.github.io/img/chris.jpg">
      

      <div class="portrait-title">
        <h2 itemprop="name">Chris Tensmeyer</h2>
        <h3 itemprop="jobTitle">Doctoral Student</h3>
        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <a href="https://byu.edu" target="_blank" itemprop="url">
            <span itemprop="name">Brigham Young University</span>
          </a>
        </h3>
        
      </div>

      <link itemprop="url" href="https://ctensmeyer.github.io/">

      <ul class="social-icon" aria-hidden="true">
        
        
        <li>
          <a itemprop="sameAs" href="tensmeyer@byu.edu" target="_blank">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a itemprop="sameAs" href="//github.com/ctensmeyer" target="_blank">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">

    

<h1 id="biography">Biography</h1>

<p>Chris Tensmeyer is a doctoral student at Brigham Young University in the Neural Networks and Machine Learning Lab.</p>


    <div class="row">

      
      <div class="col-sm-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Deep Learning</li>
          
          <li>Computer Vision</li>
          
          <li>Document Analysis and Recognition</li>
          
        </ul>
      </div>
      

      
      <div class="col-sm-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fa fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MS in Computer Science, 2016</p>
              <p class="institution">Brigham Young University</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BSc in Computer Science, 2013</p>
              <p class="institution">Brigham Young University</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  <section id="publications_selected" class="home-section">
    <div class="container">
      



<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Selected Publications</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/start_follow_read/">
        <img src="/img/line_follower.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/start_follow_read/" itemprop="url">Start, Follow, Read: End-to-End Full Page Handwriting Recognition</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        We present a deep learning model that jointly learns text detection, segmentation, and recognition using mostly images without detection or segmentation annotations.  Our Start, Follow, Read (SFR) model is composed of a Region Proposal Network to find the start position of text lines, a novel line follower network that incrementally follows and preprocesses lines of (perhaps curved) text into dewarped images suitable for recognition by a CNN-LSTM network.  SFR achieves state-of-the-art results on ICDAR2017 handwriting recognition competition dataset, even without using the provided region annotations.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Curtis Wigington, Chris Tensmeyer, Brian Davis, Bill Barrett, Brian Price, Scott Cohen
        
      </div>

      <div class="pub-publication">
        
        <em>ECCV 2018</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/start_follow_read/">
  Details
</a>








<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/~icdar2017htr/">
  ICDAR 2017 Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/4/">
  ICDAR 2016 Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database">
  IAM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.a2ialab.com/doku.php?id=rimes_database:start">
  Rimes Dataset
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/hwr_transfer/">
        <img src="/img/bentham.jpg" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/hwr_transfer/" itemprop="url">Language Model Supervision for Handwriting Recognition Model Adaptation</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        We address the problem of training handwriting recognition (HWR) models for low resource languages by leveraging data from high resource languages with similar scripts through transfer learning. A langauge model in the target language is used to refine a model trained on a source language.  Using this approach we demonstrate improved transferability among French, English, and Spanish languages using both historical and modern handwriting datasets.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer, Curtis Wigington, Brian Davis, Seth Stewart, Tony Martinez, Bill Barrett
        
      </div>

      <div class="pub-publication">
        
        <em>ICFHR 2018</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/hwr_transfer/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=12Y1i23gWmal90d-7exPwOR2Zeso9yPOs">
  PDF
</a>







<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=101KPWwd3LzZT1RGLkLB01MG8xheK5g6j">
  Slides
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database">
  IAM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.a2ialab.com/doku.php?id=rimes_database:start">
  Rimes Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.transcriptorium.eu/~tsdata/BenthamR0/">
  Bentham Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://www.prhlt.upv.es/wp/resource/the-rodrigo-corpus">
  Rodrigo Dataset
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/pagenet/">
        <img src="/img/pagenet.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/pagenet/" itemprop="url">PageNet: Page Boundary Extraction in Historical Handwritten Documents</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        In this work, we present a deep learning based system, PageNet, which identifies the main page region in an image in order to segment content from both textual and non-textual border noise. In PageNet, a Fully Convolutional Network obtains a pixel-wise segmentation which is post-processed into the output quadrilateral region.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer, Brian Davis, Curtis Wigington, Iain Lee, Bill Barrett
        
      </div>

      <div class="pub-publication">
        
        <em>HIP 2017</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/pagenet/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1709.01618">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/pagenet">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/5/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/pagenet">
  Annotations
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=12hOwhew3HWbBvsaOUTAxpxw6Y8rwDXBq">
  Slides
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/analysis_of_cnns_for_doc_images/">
        <img src="/img/cnn_filters.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/analysis_of_cnns_for_doc_images/" itemprop="url">Analysis of Convolutional Neural Networks for Document Image Classification</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Convolutional Neural Networks (CNNs) are state- of-the-art models for document image classification tasks.  However, many of these approaches rely on parameters and architectures designed for classifying natural images, which differ from document images. We question whether this is appropriate and conduct a large empirical study to find what aspects of CNNs most affect performance on document images.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer, Tony Martinez
        
      </div>

      <div class="pub-publication">
        
        <em>ICDAR 2017</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/analysis_of_cnns_for_doc_images/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03273">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/caffe">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://scs.ryerson.ca/~aharley/rvl-cdip/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1oPdjEfc4ORN4pvfavXA-t3S-5H4AfvhB">
  Poster
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/clamm/">
        <img src="/img/font_pic.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/clamm/" itemprop="url">Convolutional Neural Networks for Font Classification</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Classifying pages or text lines into font categories aids transcription because single font Optical Character Recognition (OCR) is generally more accurate than omni-font OCR.  We present a simple framework based on Convolutional Neural Networks (CNNs), where a CNN is trained to classify small patches of text into predefined font classes.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer, Daniel Saunders, Tony Martinez
        
      </div>

      <div class="pub-publication">
        
        <em>ICDAR 2017</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/clamm/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03669">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/font_classification">
  Code
</a>




<a class="btn btn-primary btn-outline btn-xs" href="http://clamm.irht.cnrs.fr/">
  CLaMM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://kafd.ideas2serve.net/">
  KAFD Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://axon.cs.byu.edu/clamm/">
  Annotations
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1GdHMeW7hVYEBVZDd9rif9YKiQ4LK_nm1">
  Slides
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/document_image_binarization_with_fully_convolutional_neural_networks/">
        <img src="/img/Binarization_Network_Arch.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/document_image_binarization_with_fully_convolutional_neural_networks/" itemprop="url">Document Image Binarization with Fully Convolutional Neural Networks</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Binarization of degraded historical manuscript images is an important pre-processing step for many document processing tasks. We formulate binarization as a pixel classification learning task and apply a novel Fully Convolutional Network (FCN) architecture that operates at multiple image scales, including full resolution. The FCN is trained to optimize a continuous version of the Pseudo F-measure metric and an ensemble of FCNs outperform the competition winners on 4 of 7 DIBCO competitions.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer, Tony Martinez
        
      </div>

      <div class="pub-publication">
        
        <em>ICDAR 2017</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/document_image_binarization_with_fully_convolutional_neural_networks/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03276">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/binarization_2017">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://vc.ee.duth.gr/dibco2017/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="http://amadi.univ-lr.fr/ICFHR2016_Contest/index.php/challenge-1">
  Dataset2
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/dibco_2017">
  Code2
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1MY4TA09bx1y13IlrB7Ksrr6MZWjgWe1h">
  Slides
</a>


      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://ctensmeyer.github.io/publication/ms_thesis/">
        <img src="/img/form.jpg" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://ctensmeyer.github.io/publication/ms_thesis/" itemprop="url">CONFIRM: Clustering of Noisy Form Images Using Robust Matching</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        Identifying the type of a scanned form greatly facilitates processing, including automated field segmentation and field recognition. Contrary to the majority of existing techniques, we focus on unsupervised type identification, where the set of form types are not known apriori, and on noisy collections that contain very similar document types. This work presents a novel algorithm: CONFIRM (Clustering Of Noisy Form Images using Robust Matching), which simultaneously discovers the types in a collection of forms and assigns each form to a type. CONFIRM matches type-set text and rule lines between forms to create domain specific features, which we show outperform Bag of Visual Word (BoVW) features employed by the current state-of-the-art.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Chris Tensmeyer
        
      </div>

      <div class="pub-publication">
        
        MS Thesis 2016
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/ms_thesis/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=7054&amp;context=etd">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/formCluster">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://www.nist.gov/srd/nist-special-database-2">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.nist.gov/srd/nist-special-database-6">
  Dataset2
</a>


      </div>

    </div>
  </div>
</div>

    
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="publications" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Recent Publications</h1>
    
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
    <ul class="fa-ul">
      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Start, Follow, Read: End-to-End Full Page Handwriting Recognition</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/start_follow_read/">
  Details
</a>








<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/~icdar2017htr/">
  ICDAR 2017 Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/4/">
  ICDAR 2016 Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database">
  IAM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.a2ialab.com/doku.php?id=rimes_database:start">
  Rimes Dataset
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Language Model Supervision for Handwriting Recognition Model Adaptation</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/hwr_transfer/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=12Y1i23gWmal90d-7exPwOR2Zeso9yPOs">
  PDF
</a>







<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=101KPWwd3LzZT1RGLkLB01MG8xheK5g6j">
  Slides
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database">
  IAM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.a2ialab.com/doku.php?id=rimes_database:start">
  Rimes Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://www.transcriptorium.eu/~tsdata/BenthamR0/">
  Bentham Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://www.prhlt.upv.es/wp/resource/the-rodrigo-corpus">
  Rodrigo Dataset
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">PageNet: Page Boundary Extraction in Historical Handwritten Documents</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/pagenet/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1709.01618">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/pagenet">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://scriptnet.iit.demokritos.gr/competitions/5/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/pagenet">
  Annotations
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=12hOwhew3HWbBvsaOUTAxpxw6Y8rwDXBq">
  Slides
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Analysis of Convolutional Neural Networks for Document Image Classification</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/analysis_of_cnns_for_doc_images/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03273">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/caffe">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://scs.ryerson.ca/~aharley/rvl-cdip/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1oPdjEfc4ORN4pvfavXA-t3S-5H4AfvhB">
  Poster
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Convolutional Neural Networks for Font Classification</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/clamm/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03669">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/font_classification">
  Code
</a>




<a class="btn btn-primary btn-outline btn-xs" href="http://clamm.irht.cnrs.fr/">
  CLaMM Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://kafd.ideas2serve.net/">
  KAFD Dataset
</a>

<a class="btn btn-primary btn-outline btn-xs" href="http://axon.cs.byu.edu/clamm/">
  Annotations
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1GdHMeW7hVYEBVZDd9rif9YKiQ4LK_nm1">
  Slides
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Document Image Binarization with Fully Convolutional Neural Networks</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/document_image_binarization_with_fully_convolutional_neural_networks/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1708.03276">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/binarization_2017">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://vc.ee.duth.gr/dibco2017/">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="http://amadi.univ-lr.fr/ICFHR2016_Contest/index.php/challenge-1">
  Dataset2
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/dibco_2017">
  Code2
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://hub.docker.com/r/tensmeyerc/icdar2017/tags/">
  Docker
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://drive.google.com/open?id=1MY4TA09bx1y13IlrB7Ksrr6MZWjgWe1h">
  Slides
</a>

</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">CONFIRM: Clustering of Noisy Form Images Using Robust Matching</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/publication/ms_thesis/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=7054&amp;context=etd">
  PDF
</a>




<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/ctensmeyer/formCluster">
  Code
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://www.nist.gov/srd/nist-special-database-2">
  Dataset
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.nist.gov/srd/nist-special-database-6">
  Dataset2
</a>

</p>
</li>

      
    </ul>
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="talks" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Recent &amp; Upcoming Talks</h1>
    
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    <h3 class="article-title" itemprop="name">
      <a href="https://ctensmeyer.github.io/talk/fhtw_18/" itemprop="url">Text Baseline Detection with Convolutional Neural Networks</a>
    </h3>

    <div class="talk-abstract" itemprop="text">
      
      Often text lines must be localized and segmented before transcription.  Detecting baselines is one way of localizing and deskewing text lines.  We present a system for detecting baselines based on a Fully Convolutional Network (FCN) followed by post processing.  We entered our system into the cBAD and HisDB competitions organized in conjunction with ICDAR 2017.  We placed 3rd and 2nd on the simple and complex layout tracks of cBAD and 2nd on the HisDB baseline detection task.
      
    </div>

    <div class="talk-event">
      
        Family History Tech Workshop 2018
      
    </div>

    <div class="talk-links">
      



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/talk/fhtw_18/">
  Details
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://docs.google.com/presentation/d/1d103gs_1cn-ctc61qmtSHo0nhVRhBKrdOF6av0prcNU/edit?usp=sharing">
  Slides
</a>




    </div>

  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    <h3 class="article-title" itemprop="name">
      <a href="https://ctensmeyer.github.io/talk/fhtw_15/" itemprop="url">CONFIRM - Clustering Of Noisy Form Images using Robust Metrics</a>
    </h3>

    <div class="talk-abstract" itemprop="text">
      
      The ability to automatically cluster large collections of noisy form images according to form type would improve the efficiency of organizations that currently do this by hand. Some noisy form collections contain form types that are structurally very similar, but should cluster apart. To address this issue, we propose CONFIRM - Clustering Of Noisy Form Images using Robust Metrics.
      
    </div>

    <div class="talk-event">
      
        Family History Tech Workshop 2015
      
    </div>

    <div class="talk-links">
      



<a class="btn btn-primary btn-outline btn-xs" href="https://ctensmeyer.github.io/talk/fhtw_15/">
  Details
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://docs.google.com/presentation/d/12PyLfpqagub0jiUY5Kl7C7eP3mGN2Xek6UuIsYKKkGU/edit?usp=sharing">
  Slides
</a>




    </div>

  </div>
</div>

    
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="teaching" class="home-section">
    <div class="container">
      


<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Teaching</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    <p>I taught CS478 (Machine Learning and Data Mining) at Brigham Young University in the Fall 2015 semester.  We covered topics such as neural networks, decision trees, K-nearest neighbor, and clustering algorithms.</p>

<p>I have also been a teaching assistant a few times:</p>

<ul>
<li>CS236: Discrete Structures</li>
<li>CS312: Algorithm Design &amp; Analysis</li>
<li>CS478: Machine Learning and Data Mining (x2)</li>
</ul>

  </div>
</div>

    </div>
  </section>

  
  
  <section id="contact" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Contact</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    <ul class="fa-ul" itemscope>

      
      <li>
        <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email" itemprop="email"><a href="mailto:tensmeyer@byu.edu">tensmeyer@byu.edu</a></span>
      </li>
      

      

      

      

      

      
      <li>
        <i class="fa-li fa fa-map-marker fa-2x" aria-hidden="true"></i>
        <span id="person-address" itemprop="address">3304 TMCB, Brigham Young University, Provo, Utah 84602, USA</span>
      </li>
      

      

    </ul>

  </div>
</div>

    </div>
  </section>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Chris Tensmeyer &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

